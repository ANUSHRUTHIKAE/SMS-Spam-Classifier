{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57b772a8",
   "metadata": {},
   "source": [
    "# SMS Spam Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aa76f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ae68cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam.csv',encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2923a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cbce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec4a1e4",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f4c5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce508d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop last 3 columns\n",
    "df.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82721de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming column names\n",
    "df.rename(columns={'v1':'target','v2':'text'},inplace=True)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ad96e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding target column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824900c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = encoder.fit_transform(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa0dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc5e69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all duplicate values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932544d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf75597",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5cbbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750d5c81",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed33d1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78baa183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalanced dataset\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfe1be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.pie(df['target'].value_counts(),labels=['ham','spam'],autopct='%0.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b1a98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98cd438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03d6e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding columns for number of characters, words and sentences\n",
    "# number of characters in text\n",
    "df['num_characters'] = df['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1315df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of words in text\n",
    "df['num_words'] = df['text'].apply(lambda x:len(nltk.word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a1290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of sentences in text\n",
    "df['num_sentences'] = df['text'].apply(lambda x:len(nltk.sent_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b1e2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1b775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analsying the number of characters, words and sentences\n",
    "df[['num_characters','num_words','num_sentences']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d737996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analsying the number of characters, words and sentences\n",
    "## for HAM\n",
    "df[df['target'] == 0][['num_characters','num_words','num_sentences']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc366718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analsying the number of characters, words and sentences\n",
    "## for SPAM\n",
    "df[df['target'] == 1][['num_characters','num_words','num_sentences']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b8b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysed that the number of characters for spam is greater than ham\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8bb9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df[df['target']==0]['num_characters'])\n",
    "sns.histplot(df[df['target']==1]['num_characters'],color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b7e1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to analyse the relationship b/w characters, words, sentences \n",
    "# can notice the presence of outliers\n",
    "sns.pairplot(df,hue='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f40fe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot an heatmap to get the correlation\n",
    "# can notice the presence of multicollinearity b/w num characters, words & sentences\n",
    "# as num_charcters is more related(0.38) with target , remove other two columns\n",
    "sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be2bb2d",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "1. Lower case\n",
    "2. Tokenization\n",
    "3. Removing special characters\n",
    "4. Removing stop words and punctuation\n",
    "5. stemming : Stripping words to their core or root meaning to improve search and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd60c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd68a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e22a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "ps.stem('loving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa1251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(text):\n",
    "    \n",
    "    # step 1: lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # step 2: tokenisation \n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    # step 3: appending the words which only have alphabets and numbers\n",
    "    text = [word for word in text if word.isalnum()]\n",
    "    \n",
    "    # step 4: appending those words which are not in stopwords and punctuation\n",
    "    text = [word for word in text if word not in stopwords.words('english') and word not in string.punctuation]\n",
    "        \n",
    "    # step 5: stem the words in the list\n",
    "    text = [ps.stem(word) for word in text]\n",
    "    \n",
    "    return \" \".join(text)\n",
    "\n",
    "\n",
    "\n",
    "# transform_text(\"hi i liked the shows enjoying how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0df31c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transformed_text'] = df['text'].apply(transform_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2c5035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wordcloud\n",
    "from wordcloud import WordCloud\n",
    "wc = WordCloud(width = 500 , height=500, min_font_size=10,background_color='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080195c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To visually highlight the most frequent and important words in text.\n",
    "# text - spam text\n",
    "spam_wc = wc.generate(df[df['target']==1]['transformed_text'].str.cat(sep=\" \"))\n",
    "plt.figure(figsize = (15,6))\n",
    "plt.imshow(spam_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3747d0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_wc = wc.generate(df[df['target']==0]['transformed_text'].str.cat(sep=\" \"))\n",
    "plt.figure(figsize = (15,6))\n",
    "plt.imshow(ham_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f90f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spam corpus to append all the words in transformed text into a list where the target is spam\n",
    "spam_corpus = [word for msg in df[df['target'] == 1]['transformed_text'].tolist() for word in msg.split()]\n",
    "\n",
    "# create ham corpus to append all the words in transformed text into a list where the target is ham\n",
    "ham_corpus = [word for msg in df[df['target'] == 0]['transformed_text'].tolist() for word in msg.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f932e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ham_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e304b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spam_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a67eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# create a dataframe with 30 most common words in spam and ham\n",
    "spam_30_df = pd.DataFrame(Counter(spam_corpus).most_common(30))\n",
    "\n",
    "ham_30_df = pd.DataFrame(Counter(ham_corpus).most_common(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c5ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_30_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f16334",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_30_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b83e7f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plotting the most commonly used 30 words\n",
    "\n",
    "sns.barplot(x = spam_30_df[0],y = spam_30_df[1])\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f98a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = ham_30_df[0],y = ham_30_df[1])\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bd1d11",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4f32f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a52ba2",
   "metadata": {},
   "source": [
    " **Here's an illustrative example:**\n",
    "\n",
    "**Imagine a corpus of three documents:**\n",
    "\n",
    "**Document 1:** \"The dog ran after the ball.\"\n",
    "\n",
    "**Document 2:** \"The cat chased the mouse.\"\n",
    "\n",
    "**Document 3:** \"The dog barked at the mailman.\"\n",
    "\n",
    "\n",
    "**Count Vectorizer representation:**\n",
    "\n",
    "| Word  | Doc 1 | Doc 2 | Doc 3 |\n",
    "|---|---|---|---|\n",
    "| the  | 2    | 2    | 2    |\n",
    "| dog  | 1    | 0    | 1    |\n",
    "| ran  | 1    | 0    | 0    |\n",
    "| after | 1    | 0    | 0    |\n",
    "| ball | 1    | 0    | 0    |\n",
    "| cat  | 0    | 1    | 0    |\n",
    "| chased | 0    | 1    | 0    |\n",
    "| mouse | 0    | 1    | 0    |\n",
    "| barked | 0    | 0    | 1    |\n",
    "| mailman | 0    | 0    | 1    |\n",
    "\n",
    "**TF-IDF representation (normalized for clarity):**\n",
    "\n",
    "| Word  | Doc 1 | Doc 2 | Doc 3 |\n",
    "|---|---|---|---|\n",
    "| the  | 0.15  | 0.15  | 0.15  |\n",
    "| dog  | 0.31  | 0     | 0.22  |\n",
    "| ran  | 0.15  | 0     | 0     |\n",
    "| after | 0.15  | 0     | 0     |\n",
    "| ball | 0.15  | 0     | 0     |\n",
    "| cat  | 0     | 0.31  | 0     |\n",
    "| chased | 0     | 0.31  | 0     |\n",
    "| mouse | 0     | 0.31  | 0     |\n",
    "| barked | 0     | 0     | 0.22  |\n",
    "| mailman | 0     | 0     | 0.22  |\n",
    "\n",
    "formula: \n",
    "\n",
    "TF(t, d) = (Number of times term t appears in document d) / (Total number of terms in document d)\n",
    "\n",
    "IDF(t) = log(Total number of documents / Number of documents with term t)\n",
    "(or) (smoothened to avoid division by zero)IDF(t) = log(1 + (Total number of documents / Number of documents with term t))\n",
    "\n",
    "TF-IDF(t, d) = TF(t, d) * IDF(t)\n",
    "\n",
    "**Key observations:**\n",
    "\n",
    "- **Count Vectorizer** gives equal weight to all words, even common ones like \"the\".\n",
    "- Represents text as raw word counts.\n",
    "- Creates a matrix where each row represents a document and each column represents a unique word in the corpus.\n",
    "- The value in each cell is the count of that word in the corresponding document.\n",
    "- Simpler approach, but doesn't account for word importance.\n",
    "- **TF-IDF** highlights more distinctive words like \"dog\", \"cat\", \"ran\", \"chased\", etc., which are more informative for understanding the content of each document.\n",
    "- Combines word frequencies with their relative importance in the corpus.\n",
    "- In this example, TF-IDF would likely be more effective for tasks like text classification or information retrieval, as it better captures the unique characteristics of each document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c969a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cv = cv.fit_transform(df['transformed_text']).toarray()\n",
    "\n",
    "# 6708 words\n",
    "X_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c25ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cv = df['target'].values\n",
    "y_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b33b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a44f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X_cv,y_cv,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57549215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aad8e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "mnb = MultinomialNB()\n",
    "bnb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd9789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.fit(X_train,y_train)\n",
    "y_pred1 = gnb.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred1))\n",
    "print(confusion_matrix(y_test,y_pred1))\n",
    "print(precision_score(y_test,y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f965d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.fit(X_train,y_train)\n",
    "y_pred2 = mnb.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred2))\n",
    "print(confusion_matrix(y_test,y_pred2))\n",
    "print(precision_score(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19e7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb.fit(X_train,y_train)\n",
    "y_pred3 = bnb.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred3))\n",
    "print(confusion_matrix(y_test,y_pred3))\n",
    "print(precision_score(y_test,y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee3b8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5f0f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = tfidf.fit_transform(df['transformed_text']).toarray()\n",
    "y_tfidf = df['target'].values\n",
    "\n",
    "# train test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_tfidf,y_tfidf,test_size=0.2,random_state=2)\n",
    "\n",
    "\n",
    "gnb = GaussianNB()\n",
    "mnb = MultinomialNB()\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "gnb.fit(X_train,y_train)\n",
    "y_pred1 = gnb.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred1))\n",
    "print(confusion_matrix(y_test,y_pred1))\n",
    "print(precision_score(y_test,y_pred1))\n",
    "\n",
    "mnb.fit(X_train,y_train)\n",
    "y_pred2 = mnb.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred2))\n",
    "print(confusion_matrix(y_test,y_pred2))\n",
    "print(precision_score(y_test,y_pred2))\n",
    "\n",
    "bnb.fit(X_train,y_train)\n",
    "y_pred3 = bnb.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred3))\n",
    "print(confusion_matrix(y_test,y_pred3))\n",
    "print(precision_score(y_test,y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673414d2",
   "metadata": {},
   "source": [
    "**In the case of Spam detection , focus is on the false positives, i.e. (Mail not spam(0) and predicted as spam(1)).We can see the precision is 1 in the case of MNB with number of false positives as 0.**\n",
    "\n",
    "## Comparing other models with MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42c2a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# !pip install xgboost\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2c9fb4",
   "metadata": {},
   "source": [
    "**BaggingClassifier**\n",
    "\n",
    "Base model: Any type of classifier can be used as the base model.\n",
    "Data sampling: Creates multiple bootstrap samples (random samples with replacement) from the training data.\n",
    "Feature sampling: Uses all features for each model.\n",
    "Combines predictions: Uses averaging (for regression) or majority voting (for classification).\n",
    "RandomForestClassifier:\n",
    "\n",
    "Base model: Uses decision trees as the base model.\n",
    "Data sampling: Same as BaggingClassifier, uses bootstrap sampling.\n",
    "Feature sampling: Randomly selects a subset of features at each split in each tree, further increasing diversity.\n",
    "Combines predictions: Same as BaggingClassifier, uses averaging or voting.\n",
    "\n",
    "**Extra Trees Classifier** (Extremely Randomized Trees) is an ensemble machine learning method that trains multiple decision trees on different subsets of the data and combines their predictions to make a final decision. It's similar to Random Forest, but with two key differences that make it even more randomized and often faster:\n",
    "\n",
    "1. Random Sampling Without Replacement:\n",
    "\n",
    "In Random Forest, each tree is trained on a random subset of data (bootstrap sample) obtained by sampling with replacement.\n",
    "Extra Trees uses random sampling without replacement, meaning each data point can only appear in one tree's training set. This creates more diversity among trees.\n",
    "\n",
    "\n",
    "2. Random Split Selection:\n",
    "\n",
    "Random Forest finds the best feature and split point for each node in a tree.\n",
    "Extra Trees selects a random split point for each feature and chooses the best one among those random splits. This further increases randomness and reduces training time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf848bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='sigmoid', gamma=1.0)\n",
    "knc = KNeighborsClassifier()\n",
    "mnb = MultinomialNB()\n",
    "dtc = DecisionTreeClassifier(max_depth=5)\n",
    "lrc = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "rfc = RandomForestClassifier(n_estimators=50, random_state=2)\n",
    "abc = AdaBoostClassifier(n_estimators=50, random_state=2)\n",
    "bc = BaggingClassifier(n_estimators=50, random_state=2)\n",
    "etc = ExtraTreesClassifier(n_estimators=50, random_state=2)\n",
    "gbdt = GradientBoostingClassifier(n_estimators=50,random_state=2)\n",
    "xgb = XGBClassifier(n_estimators=50,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27e4991",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'SVC' : svc,\n",
    "    'KN' : knc, \n",
    "    'NB': mnb, \n",
    "    'DT': dtc, \n",
    "    'LR': lrc, \n",
    "    'RF': rfc, \n",
    "    'AdaBoost': abc, \n",
    "    'BgC': bc, \n",
    "    'ETC': etc,\n",
    "    'GBDT':gbdt,\n",
    "    'xgb':xgb\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a77d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf,X_train,y_train,X_test,y_test):\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    \n",
    "    return accuracy,precision\n",
    "\n",
    "train_classifier(svc,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4388248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "for name,clf in clfs.items():\n",
    "    \n",
    "    current_accuracy,current_precision = train_classifier(clf, X_train,y_train,X_test,y_test)\n",
    "    \n",
    "    print(\"For \",name)\n",
    "    print(\"Accuracy - \",current_accuracy)\n",
    "    print(\"Precision - \",current_precision)\n",
    "    \n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    precision_scores.append(current_precision)\n",
    "\n",
    "# Create a dataframe to plot accuracy and precision of each algorithm\n",
    "performance_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy':accuracy_scores,'Precision':precision_scores}).sort_values('Precision',ascending=False)\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0c2340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to plot the performance based on accuracy and precision of each algorithm\n",
    "performance_df1 = pd.melt(performance_df, id_vars = \"Algorithm\")\n",
    "performance_df1\n",
    "\n",
    "sns.catplot(x = 'Algorithm', y='value', \n",
    "               hue = 'variable',data=performance_df1, kind='bar',height=5)\n",
    "plt.ylim(0.5,1.0)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8077334a",
   "metadata": {},
   "source": [
    "# Model Improvement\n",
    "\n",
    "* **Improvement 1 :** use max_features as 3000 in tfidf, which considers only 3000 frequently used words for vectorisation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3203f207",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775c0b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = tfidf.fit_transform(df['transformed_text']).toarray()\n",
    "y_tfidf = df['target'].values\n",
    "\n",
    "# train test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_tfidf,y_tfidf,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98d6f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "for name,clf in clfs.items():\n",
    "    \n",
    "    current_accuracy,current_precision = train_classifier(clf, X_train,y_train,X_test,y_test)\n",
    "    \n",
    "    print(\"For \",name)\n",
    "    print(\"Accuracy - \",current_accuracy)\n",
    "    print(\"Precision - \",current_precision)\n",
    "    \n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    precision_scores.append(current_precision)\n",
    "\n",
    "# Create a dataframe to plot accuracy and precision of each algorithm\n",
    "performance_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy':accuracy_scores,'Precision':precision_scores}).sort_values('Precision',ascending=False)\n",
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394dbf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to plot the performance based on accuracy and precision of each algorithm\n",
    "performance_df1 = pd.melt(performance_df, id_vars = \"Algorithm\")\n",
    "performance_df1\n",
    "\n",
    "sns.catplot(x = 'Algorithm', y='value', \n",
    "               hue = 'variable',data=performance_df1, kind='bar',height=5)\n",
    "plt.ylim(0.5,1.0)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a3cdfd",
   "metadata": {},
   "source": [
    "**The precision of random forest has decreased but MNB seems to be performing well. but previously RF was better in terms of accuracy wrt to NB. Thus not considering this improvement**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd76ad6e",
   "metadata": {},
   "source": [
    "# Improvement 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60daaab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = tfidf.fit_transform(df['transformed_text']).toarray()\n",
    "y_tfidf = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09e172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage of MinMaxscaler\n",
    "# We dont use standard scaler as it gives negative values which cant be passed into NB algorithm.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_tfidf = scaler.fit_transform(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2479297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_tfidf,y_tfidf,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b275525",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "for name,clf in clfs.items():\n",
    "    \n",
    "    current_accuracy,current_precision = train_classifier(clf, X_train,y_train,X_test,y_test)\n",
    "    \n",
    "    print(\"For \",name)\n",
    "    print(\"Accuracy - \",current_accuracy)\n",
    "    print(\"Precision - \",current_precision)\n",
    "    \n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    precision_scores.append(current_precision)\n",
    "\n",
    "# Create a dataframe to plot accuracy and precision of each algorithm\n",
    "performance_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy':accuracy_scores,'Precision':precision_scores}).sort_values('Precision',ascending=False)\n",
    "print(performance_df)\n",
    "\n",
    "# to plot the performance based on accuracy and precision of each algorithm\n",
    "performance_df1 = pd.melt(performance_df, id_vars = \"Algorithm\")\n",
    "print(performance_df1)\n",
    "\n",
    "sns.catplot(x = 'Algorithm', y='value', \n",
    "               hue = 'variable',data=performance_df1, kind='bar',height=5)\n",
    "plt.ylim(0.5,1.0)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba199d6",
   "metadata": {},
   "source": [
    "# Improvement 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce653f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending the num_character col to X_tfidf\n",
    "X_tfidf = tfidf.fit_transform(df['transformed_text']).toarray()\n",
    "X_tfidf = np.hstack((X_tfidf,df['num_characters'].values.reshape(-1,1)))\n",
    "y_tfidf = df['target'].values\n",
    "\n",
    "\n",
    "# train test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_tfidf,y_tfidf,test_size=0.2,random_state=2)\n",
    "\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "\n",
    "for name,clf in clfs.items():\n",
    "    \n",
    "    current_accuracy,current_precision = train_classifier(clf, X_train,y_train,X_test,y_test)\n",
    "    \n",
    "    print(\"For \",name)\n",
    "    print(\"Accuracy - \",current_accuracy)\n",
    "    print(\"Precision - \",current_precision)\n",
    "    \n",
    "    accuracy_scores.append(current_accuracy)\n",
    "    precision_scores.append(current_precision)\n",
    "\n",
    "# Create a dataframe to plot accuracy and precision of each algorithm\n",
    "performance_df = pd.DataFrame({'Algorithm':clfs.keys(),'Accuracy':accuracy_scores,'Precision':precision_scores}).sort_values('Precision',ascending=False)\n",
    "print(performance_df)\n",
    "\n",
    "# to plot the performance based on accuracy and precision of each algorithm\n",
    "performance_df1 = pd.melt(performance_df, id_vars = \"Algorithm\")\n",
    "print(performance_df1)\n",
    "\n",
    "sns.catplot(x = 'Algorithm', y='value', \n",
    "               hue = 'variable',data=performance_df1, kind='bar',height=5)\n",
    "plt.ylim(0.5,1.0)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06b318d",
   "metadata": {},
   "source": [
    "**From the accuracy and precision scores, we could infer that scaling or appending num_characters to the input , does not seem to improve the model .**\n",
    "\n",
    "# Improvement 4:\n",
    "\n",
    "**A voting classifier is an ensemble machine learning model that combines the predictions of multiple individual models to make a final, more robust prediction. It works by aggregating the votes or predicted probabilities from each model and then selecting the class that receives the most support.**\n",
    "\n",
    "**Types of voting strategies:**\n",
    "\n",
    "**Hard voting**: Each base model votes for a single class, and the class with the most votes wins.\n",
    "\n",
    "**Soft voting**: Each base model predicts a probability for each class, and the probabilities are averaged across models. The class with the highest average probability wins.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70889f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=50, random_state=2)\n",
    "mnb = MultinomialNB()\n",
    "etc = ExtraTreesClassifier(n_estimators=50, random_state=2)\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting = VotingClassifier(estimators=[('rf', rfc), ('nb', mnb), ('et', etc)],voting='soft')\n",
    "voting.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b40af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = voting.predict(X_test)\n",
    "print(\"Accuracy\",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision\",precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9986c0a7",
   "metadata": {},
   "source": [
    "# Improvement 5:\n",
    "simple example\n",
    "Voting: You listen to everyone's opinions and go with the most popular choice. It's like a quick poll.\n",
    "Stacking: You ask a wise mentor (meta-model) to consider everyone's suggestions and make the final decision based on their insights. It's like getting expert guidance.\n",
    "\n",
    "Train multiple \"expert\" models: Each model learns from the data in its own way.\n",
    "Collect their predictions: Each model makes predictions for the same data points.\n",
    "Create a new dataset: Use these predictions as features for a new dataset.\n",
    "Train a \"master model\": This model learns how to combine the expert predictions effectively.\n",
    "Make final predictions: When given new data, each expert model makes predictions, and the master model uses those predictions to make the ultimate decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2160b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators=[('rf', rfc), ('nb', mnb), ('et', etc)]\n",
    "final_estimator=RandomForestClassifier()\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=final_estimator)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy\",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision\",precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab2ca7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tfidf,open('application/vectorizer.pkl','wb'))\n",
    "pickle.dump(rfc,open('application/model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9653a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42896762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_sms):\n",
    "    tfidf = pickle.load(open('vectorizer.pkl','rb'))\n",
    "    model = pickle.load(open('model.pkl','rb'))\n",
    "\n",
    "    # 1. preprocess\n",
    "    transformed_sms = transform_text(input_sms)\n",
    "    # 2. vectorize\n",
    "    vector_input = tfidf.transform([transformed_sms])\n",
    "    # 3. predict\n",
    "    result = model.predict(vector_input)[0]\n",
    "    # 4. Display\n",
    "    if result == 1:\n",
    "        return \"Spam\"\n",
    "    else:\n",
    "        return \"Not Spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc031d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"sfsgdgsfbfb fgsfdgsdfg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11628b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c11387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
